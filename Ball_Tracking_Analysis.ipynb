{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn8hdV48lCA6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ebb3e9",
        "outputId": "8cf648ea-5422-48e2-87fd-7f0e3b06b082"
      },
      "source": [
        "get_ipython().system('pip install opencv-python')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd97d28f",
        "outputId": "cf067838-ffc0-43fc-f289-81b8b6c1ead6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b3b0c1a",
        "outputId": "6ae1cba3-c239-41af-c426-a7bdeca42d74"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to your zip file\n",
        "zip_file_path = '/content/drive/MyDrive/Datasets/25_nov_2025.zip'\n",
        "\n",
        "# Define the directory where you want to extract the contents\n",
        "extract_dir = '/content/drive/MyDrive/unzipped_videos'\n",
        "\n",
        "# Create the extract directory if it doesn't already exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Check if the zip file exists before proceeding\n",
        "if os.path.exists(zip_file_path):\n",
        "    try:\n",
        "        # Open the zip file in read mode and extract all contents\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "        print(f\"Files successfully unzipped from '{zip_file_path}' to '{extract_dir}'.\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: '{zip_file_path}' is not a valid zip file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during extraction: {e}\")\n",
        "else:\n",
        "    print(f\"Error: Zip file not found at '{zip_file_path}'. Skipping unzip operation.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files successfully unzipped from '/content/drive/MyDrive/Datasets/25_nov_2025.zip' to '/content/drive/MyDrive/unzipped_videos'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14c9cc23"
      },
      "source": [
        "## Collect Video File Paths from Unzipped Folder\n",
        "\n",
        "### Subtask:\n",
        "List all video files within the newly unzipped folder (`/content/drive/MyDrive/unzipped_videos`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95cb926a"
      },
      "source": [
        "**Reasoning**:\n",
        "To list the video files within the unzipped folder, I will reuse the `get_video_files` function that was previously defined. This function will take the `extract_dir` as input and return a list of video file paths.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9132cfc3",
        "outputId": "9dfed8d9-1165-4338-af21-d348a0c8b198"
      },
      "source": [
        "import os\n",
        "\n",
        "def get_video_files(folder_path):\n",
        "    \"\"\"\n",
        "    Prompts the user for a folder path and returns a list of video file paths within it.\n",
        "    \"\"\"\n",
        "    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm', '.3gp', '.mpeg', '.ogv')\n",
        "    video_files = []\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: The path '{folder_path}' does not exist. Please check the path and try again.\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Searching for video files in: {folder_path}\")\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(video_extensions):\n",
        "                video_files.append(os.path.join(root, file))\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"No video files found with extensions {video_extensions} in '{folder_path}' or its subdirectories.\")\n",
        "\n",
        "    return video_files\n",
        "\n",
        "# Assuming 'extract_dir' is already defined from the previous step as '/content/drive/MyDrive/unzipped_videos'\n",
        "video_file_paths = get_video_files(extract_dir)\n",
        "\n",
        "print(\"\\nFound video files in the unzipped folder:\")\n",
        "if video_file_paths:\n",
        "    for i, file_path in enumerate(video_file_paths):\n",
        "        print(f\"{i+1}. {file_path}\")\n",
        "else:\n",
        "    print(\"No video files found in the unzipped folder.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for video files in: /content/drive/MyDrive/unzipped_videos\n",
            "\n",
            "Found video files in the unzipped folder:\n",
            "1. /content/drive/MyDrive/unzipped_videos/25_nov_2025/4.mov\n",
            "2. /content/drive/MyDrive/unzipped_videos/25_nov_2025/5.mov\n",
            "3. /content/drive/MyDrive/unzipped_videos/25_nov_2025/7.mov\n",
            "4. /content/drive/MyDrive/unzipped_videos/25_nov_2025/6.mov\n",
            "5. /content/drive/MyDrive/unzipped_videos/25_nov_2025/2.mov\n",
            "6. /content/drive/MyDrive/unzipped_videos/25_nov_2025/3.mov\n",
            "7. /content/drive/MyDrive/unzipped_videos/25_nov_2025/8.mov\n",
            "8. /content/drive/MyDrive/unzipped_videos/25_nov_2025/9.mov\n",
            "9. /content/drive/MyDrive/unzipped_videos/25_nov_2025/14.mov\n",
            "10. /content/drive/MyDrive/unzipped_videos/25_nov_2025/15.mov\n",
            "11. /content/drive/MyDrive/unzipped_videos/25_nov_2025/13.mov\n",
            "12. /content/drive/MyDrive/unzipped_videos/25_nov_2025/11.mov\n",
            "13. /content/drive/MyDrive/unzipped_videos/25_nov_2025/10.mov\n",
            "14. /content/drive/MyDrive/unzipped_videos/25_nov_2025/1.mp4\n",
            "15. /content/drive/MyDrive/unzipped_videos/25_nov_2025/12.mov\n",
            "16. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._1.mp4\n",
            "17. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._4.mov\n",
            "18. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._5.mov\n",
            "19. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._7.mov\n",
            "20. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._6.mov\n",
            "21. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._2.mov\n",
            "22. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._3.mov\n",
            "23. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._8.mov\n",
            "24. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._14.mov\n",
            "25. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._9.mov\n",
            "26. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._15.mov\n",
            "27. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._12.mov\n",
            "28. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._13.mov\n",
            "29. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._11.mov\n",
            "30. /content/drive/MyDrive/unzipped_videos/__MACOSX/25_nov_2025/._10.mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b1d5c15"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step listed video files, but included macOS specific metadata files (e.g., `.__MACOSX` directory and `._` prefixed files) which are not actual video files. To accurately collect only valid video file paths for further processing, I need to refine the `get_video_files` function to filter out these irrelevant files. This will ensure that only actual video files are considered for analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d08bfca",
        "outputId": "9a253ce7-b71e-437a-c773-2ab4ca11edd7"
      },
      "source": [
        "import os\n",
        "\n",
        "def get_video_files(folder_path):\n",
        "    \"\"\"\n",
        "    Returns a list of actual video file paths within a given folder, filtering out macOS specific files.\n",
        "    \"\"\"\n",
        "    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm', '.3gp', '.mpeg', '.ogv')\n",
        "    video_files = []\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: The path '{folder_path}' does not exist. Please check the path and try again.\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Searching for video files in: {folder_path}\")\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            # Exclude macOS resource fork files (prefixed with ._) and files inside __MACOSX directory\n",
        "            if not file.startswith('._') and '__MACOSX' not in root:\n",
        "                if file.lower().endswith(video_extensions):\n",
        "                    video_files.append(os.path.join(root, file))\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"No actual video files found with extensions {video_extensions} in '{folder_path}' or its subdirectories after filtering.\")\n",
        "\n",
        "    return video_files\n",
        "\n",
        "# Assuming 'extract_dir' is already defined from the previous step as '/content/drive/MyDrive/unzipped_videos'\n",
        "video_file_paths = get_video_files(extract_dir)\n",
        "\n",
        "print(\"\\nFound actual video files in the unzipped folder after filtering:\")\n",
        "if video_file_paths:\n",
        "    for i, file_path in enumerate(video_file_paths):\n",
        "        print(f\"{i+1}. {file_path}\")\n",
        "else:\n",
        "    print(\"No actual video files found in the unzipped folder after filtering.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for video files in: /content/drive/MyDrive/unzipped_videos\n",
            "\n",
            "Found actual video files in the unzipped folder after filtering:\n",
            "1. /content/drive/MyDrive/unzipped_videos/25_nov_2025/4.mov\n",
            "2. /content/drive/MyDrive/unzipped_videos/25_nov_2025/5.mov\n",
            "3. /content/drive/MyDrive/unzipped_videos/25_nov_2025/7.mov\n",
            "4. /content/drive/MyDrive/unzipped_videos/25_nov_2025/6.mov\n",
            "5. /content/drive/MyDrive/unzipped_videos/25_nov_2025/2.mov\n",
            "6. /content/drive/MyDrive/unzipped_videos/25_nov_2025/3.mov\n",
            "7. /content/drive/MyDrive/unzipped_videos/25_nov_2025/8.mov\n",
            "8. /content/drive/MyDrive/unzipped_videos/25_nov_2025/9.mov\n",
            "9. /content/drive/MyDrive/unzipped_videos/25_nov_2025/14.mov\n",
            "10. /content/drive/MyDrive/unzipped_videos/25_nov_2025/15.mov\n",
            "11. /content/drive/MyDrive/unzipped_videos/25_nov_2025/13.mov\n",
            "12. /content/drive/MyDrive/unzipped_videos/25_nov_2025/11.mov\n",
            "13. /content/drive/MyDrive/unzipped_videos/25_nov_2025/10.mov\n",
            "14. /content/drive/MyDrive/unzipped_videos/25_nov_2025/1.mp4\n",
            "15. /content/drive/MyDrive/unzipped_videos/25_nov_2025/12.mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43d75ef5"
      },
      "source": [
        "**Reasoning**:\n",
        "To extract the FPS and resolution for each video file, I will iterate through the `video_file_paths` list, use `cv2.VideoCapture` to open each video, retrieve the `CAP_PROP_FPS`, `CAP_PROP_FRAME_WIDTH`, and `CAP_PROP_FRAME_HEIGHT` properties, and store the results in a list of dictionaries, handling any potential errors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86644cf3",
        "outputId": "0c717291-20d2-455b-f6e7-322bb27ca5cf"
      },
      "source": [
        "import cv2\n",
        "\n",
        "video_metadata = []\n",
        "\n",
        "for video_path in video_file_paths:\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file: {video_path}\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        video_metadata.append({\n",
        "            'file_path': video_path,\n",
        "            'fps': fps,\n",
        "            'width': width,\n",
        "            'height': height\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {video_path}: {e}\")\n",
        "    finally:\n",
        "        cap.release()\n",
        "\n",
        "print(\"Extracted metadata for video files:\")\n",
        "for metadata in video_metadata:\n",
        "    print(metadata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted metadata for video files:\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/1.mp4', 'fps': 25.0, 'width': 1920, 'height': 1080}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/4.mov', 'fps': 56.38297872340426, 'width': 2560, 'height': 1600}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/5.mov', 'fps': 57.411764705882355, 'width': 2560, 'height': 1600}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/7.mov', 'fps': 43.40425531914894, 'width': 2560, 'height': 1416}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/6.mov', 'fps': 38.2010582010582, 'width': 2560, 'height': 1440}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/2.mov', 'fps': 57.077922077922075, 'width': 2560, 'height': 1600}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/3.mov', 'fps': 56.95652173913044, 'width': 2560, 'height': 1600}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/8.mov', 'fps': 42.22222222222222, 'width': 2560, 'height': 1440}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/9.mov', 'fps': 40.94292803970223, 'width': 2560, 'height': 1440}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/14.mov', 'fps': 49.0, 'width': 2558, 'height': 1442}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/15.mov', 'fps': 44.01639344262295, 'width': 2560, 'height': 1440}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/12.mov', 'fps': 47.11864406779661, 'width': 2560, 'height': 1440}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/13.mov', 'fps': 44.315352697095435, 'width': 2560, 'height': 1440}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/11.mov', 'fps': 44.81012658227848, 'width': 2558, 'height': 1444}\n",
            "{'file_path': '/content/drive/MyDrive/unzipped_videos/25_nov_2025/10.mov', 'fps': 42.526315789473685, 'width': 2560, 'height': 1440}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f28eecd2"
      },
      "source": [
        "**Reasoning**:\n",
        "The video metadata has been extracted and stored in a list of dictionaries. To display this information in a clear, tabular format as requested by the main task, I will convert this list into a pandas DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36b2b052",
        "outputId": "a592eba1-a5f5-4ea2-94d9-11d998951362"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_video_metadata = pd.DataFrame(video_metadata)\n",
        "\n",
        "print(\"Video Metadata Table:\")\n",
        "print(df_video_metadata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Metadata Table:\n",
            "                                            file_path        fps  width  \\\n",
            "0   /content/drive/MyDrive/unzipped_videos/25_nov_...  25.000000   1920   \n",
            "1   /content/drive/MyDrive/unzipped_videos/25_nov_...  56.382979   2560   \n",
            "2   /content/drive/MyDrive/unzipped_videos/25_nov_...  57.411765   2560   \n",
            "3   /content/drive/MyDrive/unzipped_videos/25_nov_...  43.404255   2560   \n",
            "4   /content/drive/MyDrive/unzipped_videos/25_nov_...  38.201058   2560   \n",
            "5   /content/drive/MyDrive/unzipped_videos/25_nov_...  57.077922   2560   \n",
            "6   /content/drive/MyDrive/unzipped_videos/25_nov_...  56.956522   2560   \n",
            "7   /content/drive/MyDrive/unzipped_videos/25_nov_...  42.222222   2560   \n",
            "8   /content/drive/MyDrive/unzipped_videos/25_nov_...  40.942928   2560   \n",
            "9   /content/drive/MyDrive/unzipped_videos/25_nov_...  49.000000   2558   \n",
            "10  /content/drive/MyDrive/unzipped_videos/25_nov_...  44.016393   2560   \n",
            "11  /content/drive/MyDrive/unzipped_videos/25_nov_...  47.118644   2560   \n",
            "12  /content/drive/MyDrive/unzipped_videos/25_nov_...  44.315353   2560   \n",
            "13  /content/drive/MyDrive/unzipped_videos/25_nov_...  44.810127   2558   \n",
            "14  /content/drive/MyDrive/unzipped_videos/25_nov_...  42.526316   2560   \n",
            "\n",
            "    height  \n",
            "0     1080  \n",
            "1     1600  \n",
            "2     1600  \n",
            "3     1416  \n",
            "4     1440  \n",
            "5     1600  \n",
            "6     1600  \n",
            "7     1440  \n",
            "8     1440  \n",
            "9     1442  \n",
            "10    1440  \n",
            "11    1440  \n",
            "12    1440  \n",
            "13    1444  \n",
            "14    1440  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ims27hD3BHo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a863b0ba"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the basic video EDA performed, highlighting the FPS and resolution for each video analyzed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caeaa35b"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The basic video EDA performed involved unzipping the video archive, collecting video file paths while filtering out irrelevant system files, and then extracting key metadata for each video. For each video analyzed, its Frames Per Second (FPS) and resolution (width and height) were successfully extracted and compiled into a tabular format.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `opencv-python` library, essential for video processing, was found to be already installed.\n",
        "*   The video archive `25_nov_2025.zip` was successfully unzipped from `/content/drive/MyDrive/Datasets/` to the designated directory `/content/drive/MyDrive/unzipped_videos`.\n",
        "*   The video file collection process was refined to accurately identify actual video files by excluding macOS-specific metadata files (e.g., those starting with `._` or located in `__MACOSX` directories).\n",
        "*   For every identified video file, its Frames Per Second (FPS), width, and height (resolution) were successfully extracted using `cv2.VideoCapture`.\n",
        "*   All extracted video metadata, including file path, FPS, width, and height, was systematically organized and presented in a pandas DataFrame for clear summarization.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The established process provides a foundational step for comprehensive video dataset management and quality control, ensuring that subsequent analyses leverage accurate video specifications.\n",
        "*   Further analysis could involve calculating descriptive statistics for FPS and resolution across the dataset to understand the video characteristics and identify potential variations or standardization needs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training\n"
      ],
      "metadata": {
        "id": "qLjmVHAt-kyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmSEGMYMAGID",
        "outputId": "23b7abb6-b273-4c91-d5e5-3ce0e42da6a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.243-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.243-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.243 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Roboflow Dataset from Drive"
      ],
      "metadata": {
        "id": "ISNyXmBQR1Ap"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_2",
        "outputId": "4bf225de-fa10-43a7-d0e5-33584b584c11"
      },
      "source": [
        "import os\n",
        "\n",
        "dataset_folder_path = input(\"Please enter the full path to your dataset folder in Google Drive (e.g., /content/drive/MyDrive/Datasets/dataset): \")\n",
        "\n",
        "# Construct the full path to data.yaml\n",
        "data_yaml_path = os.path.join(dataset_folder_path, 'data.yaml')\n",
        "\n",
        "print(f\"Using data.yaml path: {data_yaml_path}\")\n",
        "\n",
        "# Ensure the path exists, otherwise warn the user\n",
        "if not os.path.exists(data_yaml_path):\n",
        "    print(f\"Warning: The file '{data_yaml_path}' does not exist. Please double-check your dataset path and the location of data.yaml within it.\")\n",
        "else:\n",
        "    print(\"Path to data.yaml verified.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the full path to your dataset folder in Google Drive (e.g., /content/drive/MyDrive/Datasets/dataset): /content/drive/MyDrive/Datasets/dataset\n",
            "Using data.yaml path: /content/drive/MyDrive/Datasets/dataset/data.yaml\n",
            "Path to data.yaml verified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training on Roboflow Dataset\n",
        "\n",
        " - Fine-tuning pre-trained Yolo (yolov8n) model"
      ],
      "metadata": {
        "id": "XZBK8uyiR6S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Me kitta\n",
        "\n",
        "\"\"\"\n",
        "Optional training script for fine-tuning YOLOv8n on cricket ball dataset.\n",
        "This should NOT be run on test videos.\n",
        "\"\"\"\n",
        "\n",
        "def train_model():\n",
        "    \"\"\"\n",
        "    Train YOLOv8n on cricket ball dataset from Roboflow.\n",
        "\n",
        "    \"\"\"\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    # Load pretrained YOLOv8n\n",
        "    model = YOLO('yolov8n.pt')\n",
        "\n",
        "    # Train\n",
        "    results = model.train(\n",
        "        # data='dataset/data.yaml',\n",
        "        data=data_yaml_path,\n",
        "        epochs=50,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        device='cuda',  # Use 'cuda' if GPU available during training\n",
        "        patience=10,\n",
        "        save=True,\n",
        "        project='runs/train',\n",
        "        name='cricket_ball',\n",
        "        exist_ok=True,\n",
        "        pretrained=True,\n",
        "        optimizer='Adam',\n",
        "        lr0=0.001,\n",
        "        weight_decay=0.0005,\n",
        "        workers=2  # Low for CPU\n",
        "    )\n",
        "\n",
        "    print(\"Training complete!\")\n",
        "    print(f\"Best model saved at: runs/train/cricket_ball/weights/best.pt\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiW_213S-ka3",
        "outputId": "1cd69d93-539e-4ddb-bc16-1d5c43a3bcc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 114.3MB/s 0.1s\n",
            "Ultralytics 8.3.241 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/Datasets/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=cricket_ball, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/train/cricket_ball, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 28.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 96.5MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 3.6Â±7.9 MB/s, size: 38.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Datasets/dataset/train/labels.cache... 199 images, 6 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 199/199 187.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.3 ms, read: 0.1Â±0.0 MB/s, size: 25.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Datasets/dataset/valid/labels.cache... 28 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 28/28 33.5Kit/s 0.0s\n",
            "Plotting labels to /content/runs/train/cricket_ball/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/train/cricket_ball\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      1.99G      2.211       6.04      1.285          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 2.4it/s 5.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.2s/it 12.2s\n",
            "                   all         28         26          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.34G      1.906      2.741      1.183          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.0it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
            "                   all         28         26          1     0.0385      0.519      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.35G      1.839      2.182       1.19          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.2it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
            "                   all         28         26          1     0.0385      0.519      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.35G      1.826      1.833      1.193         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.1it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.4it/s 0.2s\n",
            "                   all         28         26      0.722        0.5      0.594      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.37G      1.801      1.654      1.228          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.5it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
            "                   all         28         26      0.444      0.769      0.668      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.37G       1.84      1.688      1.158          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.0it/s 3.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
            "                   all         28         26      0.417      0.769      0.614      0.326\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.37G      1.807      1.592      1.186         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 5.1it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5it/s 0.2s\n",
            "                   all         28         26      0.293      0.923      0.675      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      2.37G      1.761      1.406      1.192          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
            "                   all         28         26      0.822      0.356      0.701      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.37G      1.648      1.367      1.178         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.0it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
            "                   all         28         26      0.713      0.692      0.778      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.37G      1.722      1.455      1.182          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.4it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
            "                   all         28         26      0.684      0.654      0.727      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.39G      1.653      1.358      1.206          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
            "                   all         28         26      0.695      0.577      0.689      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      2.39G      1.655       1.25      1.151          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 5.0it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.9it/s 0.2s\n",
            "                   all         28         26      0.774      0.659      0.769      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      2.39G      1.603      1.276      1.121         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.4it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
            "                   all         28         26      0.726      0.769      0.749      0.405\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.39G      1.579      1.173      1.168         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 5.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
            "                   all         28         26      0.845      0.808      0.885      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.39G      1.598      1.167      1.123         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.9it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
            "                   all         28         26      0.825      0.728      0.818      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      2.41G      1.577       1.11      1.135          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.4it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
            "                   all         28         26      0.838      0.796      0.887      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.41G      1.677      1.204      1.136          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.7it/s 3.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.3it/s 0.2s\n",
            "                   all         28         26       0.84      0.806      0.881      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      2.43G      1.555      1.073      1.109          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 5.4it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
            "                   all         28         26      0.814      0.846      0.829      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.43G      1.584      1.085      1.159          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.9it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
            "                   all         28         26      0.742      0.808      0.785      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.43G      1.538      1.026      1.125         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.0it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
            "                   all         28         26       0.74      0.731      0.788      0.358\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.43G      1.541      1.012       1.11         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.6it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
            "                   all         28         26       0.76      0.615      0.702       0.34\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      2.43G      1.434     0.9712      1.089         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 4.5it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.9it/s 0.2s\n",
            "                   all         28         26      0.829      0.808      0.866      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      2.44G      1.454      1.005      1.054          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 5.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
            "                   all         28         26       0.91      0.885      0.928      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      2.44G      1.535      1.027      1.118          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 3.8it/s 3.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
            "                   all         28         26      0.918      0.885      0.936      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      2.44G      1.408      1.043      1.092          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 13/13 5.1it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
            "                   all         28         26      0.788      0.923       0.89      0.404\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 15, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "25 epochs completed in 0.033 hours.\n",
            "Optimizer stripped from /content/runs/train/cricket_ball/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/train/cricket_ball/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/train/cricket_ball/weights/best.pt...\n",
            "Ultralytics 8.3.241 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
            "                   all         28         26      0.826      0.729       0.83      0.452\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/train/cricket_ball\u001b[0m\n",
            "Training complete!\n",
            "Best model saved at: runs/train/cricket_ball/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62b32cc5",
        "outputId": "ef029c44-ad66-4303-c1cf-e827e3c7c4bb"
      },
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Define the path to the best performing model weights\n",
        "model_path = 'runs/train/cricket_ball/weights/best.pt'\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "print(f\"YOLO model loaded successfully from: {model_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO model loaded successfully from: runs/train/cricket_ball/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "567b94f9",
        "outputId": "83b743cb-9a3f-4d91-df98-ac09d70018ed"
      },
      "source": [
        "def predict_on_video(video_path):\n",
        "    \"\"\"\n",
        "    Performs object detection predictions on each frame of a given video file.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): The file path to the video.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of prediction results for each frame.\n",
        "    \"\"\"\n",
        "    print(f\"Performing predictions on video: {video_path}\")\n",
        "    # The model object is assumed to be loaded globally from the previous step\n",
        "    results = model.predict(source=video_path, imgsz=640, stream=True)\n",
        "    return results\n",
        "\n",
        "print(\"Function 'predict_on_video' defined successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'predict_on_video' defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2017de7"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `predict_on_video` function is defined, I will iterate through the `video_file_paths` list and call this function for each video, storing all the prediction results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f350c62",
        "outputId": "e3f04885-482b-4cc5-e6e9-75cfcae1dfff"
      },
      "source": [
        "import os\n",
        "\n",
        "def get_video_files(folder_path):\n",
        "    \"\"\"\n",
        "    Returns a list of actual video file paths within a given folder, filtering out macOS specific files.\n",
        "    \"\"\"\n",
        "    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm', '.3gp', '.mpeg', '.ogv')\n",
        "    video_files = []\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: The path '{folder_path}' does not exist. Please check the path and try again.\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Searching for video files in: {folder_path}\")\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            # Exclude macOS resource fork files (prefixed with ._) and files inside __MACOSX directory\n",
        "            if not file.startswith('._') and '__MACOSX' not in root:\n",
        "                if file.lower().endswith(video_extensions):\n",
        "                    video_files.append(os.path.join(root, file))\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"No actual video files found with extensions {video_extensions} in '{folder_path}' or its subdirectories after filtering.\")\n",
        "\n",
        "    return video_files\n",
        "\n",
        "# Re-define extract_dir as it might have been lost in the kernel state\n",
        "extract_dir = '/content/drive/MyDrive/unzipped_videos'\n",
        "\n",
        "# Re-populate video_file_paths using the defined get_video_files function\n",
        "video_file_paths = get_video_files(extract_dir)\n",
        "\n",
        "all_video_prediction_results = []\n",
        "\n",
        "for video_path in video_file_paths:\n",
        "    predictions = predict_on_video(video_path)\n",
        "    # Store predictions along with the video path for later reference\n",
        "    all_video_prediction_results.append({\n",
        "        'video_path': video_path,\n",
        "        'predictions': predictions\n",
        "    })\n",
        "\n",
        "print(\"Predictions completed for all videos.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for video files in: /content/drive/MyDrive/unzipped_videos\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/1.mp4\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/4.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/5.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/7.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/6.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/2.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/3.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/8.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/9.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/14.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/15.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/12.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/13.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/11.mov\n",
            "Performing predictions on video: /content/drive/MyDrive/unzipped_videos/25_nov_2025/10.mov\n",
            "Predictions completed for all videos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roboflow EDA"
      ],
      "metadata": {
        "id": "xmGyOl1ATR8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# dataset_folder_path = input(\"Please enter the full path to your dataset folder in Google Drive (e.g., /content/drive/MyDrive/Datasets/dataset): \")\n",
        "\n",
        "dataset_folder_path = \"/content/drive/MyDrive/Datasets/dataset\"\n",
        "\n",
        "# Construct the full path to data.yaml\n",
        "data_yaml_path = os.path.join(dataset_folder_path, 'data.yaml')\n",
        "\n",
        "print(f\"Using data.yaml path: {data_yaml_path}\")\n",
        "\n",
        "# Ensure the path exists, otherwise warn the user\n",
        "if not os.path.exists(data_yaml_path):\n",
        "    print(f\"Warning: The file '{data_yaml_path}' does not exist. Please double-check your dataset path and the location of data.yaml within it.\")\n",
        "else:\n",
        "    print(\"Path to data.yaml verified.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAUF9BGqEGx8",
        "outputId": "2653bafa-bddb-4f96-e2ea-81f97f3fa04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the full path to your dataset folder in Google Drive (e.g., /content/drive/MyDrive/Datasets/dataset): /content/drive/MyDrive/Datasets/dataset\n",
            "Using data.yaml path: /content/drive/MyDrive/Datasets/dataset/data.yaml\n",
            "Path to data.yaml verified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "  data = yaml.safe_load(f)\n",
        "\n",
        "print(\"dataset YAML contents: \\n\")\n",
        "for k, v in data.items():\n",
        "  print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20rfMfH8EOpa",
        "outputId": "1dff8072-6298-48aa-fc67-9b873489a048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset YAML contents: \n",
            "\n",
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "test: ../test/images\n",
            "nc: 1\n",
            "names: ['Cricket-Ball']\n",
            "roboflow: {'workspace': 'project', 'project': 'cricket-ball-detection-8uv1o', 'version': 2, 'license': 'Public Domain', 'url': 'https://universe.roboflow.com/project/cricket-ball-detection-8uv1o/dataset/2'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "image_extension = ('*.jpg', '*.jpeg', '*.png')\n",
        "\n",
        "def get_images(folder):\n",
        "  images = []\n",
        "  for ext in image_extension:\n",
        "    images.extend(glob(os.path.join(folder, ext)))\n",
        "  return images\n",
        "\n",
        "train_images = get_images(os.path.join(dataset_folder_path, 'train', 'images'))\n",
        "val_images   = get_images(os.path.join(dataset_folder_path, 'valid', 'images'))\n",
        "test_images  = get_images(os.path.join(dataset_folder_path, 'test', 'images'))\n",
        "\n",
        "print(f\"Train images: {len(train_images)}\")\n",
        "print(f\"Valid images: {len(val_images)}\")\n",
        "print(f\"Test images : {len(test_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGdNmx3ZE3rH",
        "outputId": "fcbf6b7a-ddf6-4b9e-fa44-c64e4b943232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 199\n",
            "Valid images: 28\n",
            "Test images : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "heights, widths, channels = [], [], []\n",
        "\n",
        "for img_path in train_images:\n",
        "  img = cv2.imread(img_path)\n",
        "  if img is None:\n",
        "    continue\n",
        "  h, w, c = img.shape\n",
        "  heights.append(h)\n",
        "  widths.append(w)\n",
        "  channels.append(c)\n",
        "\n",
        "print(\"Image shape statistics (TRAIN):\")\n",
        "print(f\"Min resolution : {min(widths)} x {min(heights)}\")\n",
        "print(f\"Max resolution : {max(widths)} x {max(heights)}\")\n",
        "print(f\"Mean resolution: {int(np.mean(widths))} x {int(np.mean(heights))}\")\n",
        "print(f\"Channel counts : {Counter(channels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNUdSQG-FZC2",
        "outputId": "a55e4044-0021-4d2e-d76b-bd11d003569e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape statistics (TRAIN):\n",
            "Min resolution : 640 x 640\n",
            "Max resolution : 640 x 640\n",
            "Mean resolution: 640 x 640\n",
            "Channel counts : Counter({3: 199})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aspect_ratios = [w / h for w, h in zip(widths, heights)]\n",
        "\n",
        "print(f\"Aspect ratio range: {min(aspect_ratios):.2f} â†’ {max(aspect_ratios):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G94QSvuVF6qN",
        "outputId": "cd2a3a14-471f-48f8-b59e-383a1379bd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect ratio range: 1.00 â†’ 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(aspect_ratios, bins=20)\n",
        "plt.xlabel(\"Aspect Ratio (W/H)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Aspect Ratio Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "UQo6ntnDGfRY",
        "outputId": "1f3c9dbc-db3b-4363-9f17-e90a53381bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARDpJREFUeJzt3XlcVeXe///3BmSDyiAKIkcU5yHNypIsU0yT1Giyk5oamGUlaulp8jQ4VZqVWeZQ5xhmOZTdTpmZOGeiOXtriopjX0FNBRQVGa7fH/3cdzvQZAtuWL2ej8d6HPa1rrXWZy3o7LfXutbeNmOMEQAAgEV5uLsAAACAkkTYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAVCmREVFKSoqyq01REREKC4ursSPc/DgQdlsNk2dOtXRFhcXp4oVK5b4sS+x2WwaNmzYdTseUBIIO0AJmDhxomw2myIjI91dSpGtXbtWw4YNU3p6+lX1j4uLk81mcyx2u13169fXG2+8oQsXLrhUwy+//KJhw4bp4MGDLm1fFFFRUY7aPTw85O/vrwYNGqhXr15KTEwstuMsWrSo1IaG0lwbUBy83F0AYEXTp09XRESEfv75Z+3bt09169Z1d0lXbe3atRo+fLji4uIUGBh4VdvY7Xb997//lSRlZGRo/vz5GjlypFJSUjR9+vQi1/DLL79o+PDhioqKUkREhNO6JUuWFHl/f6V69eoaNWqUJCkrK0v79u3TnDlz9OWXX+rRRx/Vl19+qXLlyjn6Jycny8OjaP9WXLRokSZMmFCkUFGzZk2dP3/e6dgl4Uq1nT9/Xl5evFWgbOMvGChmBw4c0Nq1azVnzhw9/fTTmj59uoYOHeruskqUl5eXevbs6Xjdr18/3XHHHZo5c6bGjh2rqlWrFtuxvL29i21flwQEBDjVL0mjR4/WwIEDNXHiREVEROidd95xrLPb7cVewx/l5uYqPz9f3t7e8vHxKdFj/RV3Hx8oDtzGAorZ9OnTValSJXXu3FmPPPLIZUc2Zs2apebNm8vPz0/+/v5q2rSpPvzwQ8f6qVOnymazafXq1Xr66adVuXJl+fv76/HHH9fp06cL7O/777/XXXfdpQoVKsjPz0+dO3fWzp07C/TbvXu3Hn30UQUHB8vX11cNGjTQq6++KkkaNmyYXnzxRUlSrVq1HLd3ino7yWazqVWrVjLGaP/+/Y72Q4cOqV+/fmrQoIF8fX1VuXJl/fOf/3Ta/9SpU/XPf/5TktS2bVtHDStXrpRU+Jyd48ePq0+fPqpatap8fHzUrFkzff7550Wq+c88PT310UcfqXHjxvr444+VkZHhWPfnOTs5OTkaPny46tWrJx8fH1WuXFmtWrVy3AaLi4vThAkTHNfm0iL937yc9957T+PGjVOdOnVkt9v1yy+/FDpn55L9+/crOjpaFSpUUFhYmEaMGCFjjGP9ypUrna7bJX/e55Vqu9T25xGfLVu2qGPHjvL391fFihXVrl07rVu3zqnPpb/fn376SYMHD1ZwcLAqVKighx56SCdOnPjrXwBQjBjZAYrZ9OnT9fDDD8vb21vdu3fXpEmTtGHDBt12222OPomJierevbvatWvnGDHYtWuXfvrpJz333HNO++vfv78CAwM1bNgwJScna9KkSTp06JDjzUySvvjiC8XGxio6OlrvvPOOzp07p0mTJqlVq1basmWL41bQ9u3bddddd6lcuXLq27evIiIilJKSom+//VZvvfWWHn74Ye3Zs0czZ87UBx98oCpVqkiSgoODi3wdLgWYSpUqOdo2bNigtWvXqlu3bqpevboOHjyoSZMmKSoqSr/88ovKly+v1q1ba+DAgfroo4/073//W40aNZIkx//+2fnz5xUVFaV9+/apf//+qlWrlmbPnq24uDilp6cXuJ5F4enpqe7du+v111/XmjVr1Llz50L7DRs2TKNGjdKTTz6pFi1aKDMzUxs3btTmzZt1zz336Omnn9bRo0eVmJioL774otB9JCQk6MKFC+rbt6/sdruCgoKUn59faN+8vDzde++9uv322zVmzBgtXrxYQ4cOVW5urkaMGFGkc7ya2v5o586duuuuu+Tv76+XXnpJ5cqV0yeffKKoqCitWrWqwDy1AQMGqFKlSho6dKgOHjyocePGqX///vrqq6+KVCdwTQyAYrNx40YjySQmJhpjjMnPzzfVq1c3zz33nFO/5557zvj7+5vc3NzL7ishIcFIMs2bNzcXL150tI8ZM8ZIMvPnzzfGGHPmzBkTGBhonnrqKaft09LSTEBAgFN769atjZ+fnzl06JBT3/z8fMfP7777rpFkDhw4cFXnHBsbaypUqGBOnDhhTpw4Yfbt22fee+89Y7PZTJMmTZz2fe7cuQLbJyUlGUlm2rRpjrbZs2cbSWbFihUF+rdp08a0adPG8XrcuHFGkvnyyy8dbRcvXjQtW7Y0FStWNJmZmVesv02bNuaGG2647Pq5c+caSebDDz90tNWsWdPExsY6Xjdr1sx07tz5iseJj483hf1f7oEDB4wk4+/vb44fP17ouoSEBEdbbGyskWQGDBjgaMvPzzedO3c23t7e5sSJE8YYY1asWFHoNSxsn5erzRhjJJmhQ4c6Xj/44IPG29vbpKSkONqOHj1q/Pz8TOvWrR1tl/5+27dv7/Q3MGjQIOPp6WnS09MLPR5QEriNBRSj6dOnq2rVqmrbtq2k328BdO3aVbNmzVJeXp6jX2BgoLKysq7qaZ++ffs6TVB99tln5eXlpUWLFkn6fZQoPT1d3bt312+//eZYPD09FRkZqRUrVkiSTpw4odWrV+uJJ55QjRo1nI7xx9sWrsjKylJwcLCCg4NVt25dvfDCC7rzzjs1f/58p337+vo6fs7JydHJkydVt25dBQYGavPmzS4de9GiRQoNDVX37t0dbeXKldPAgQN19uxZrVq1yvUTkxyPeZ85c+ayfQIDA7Vz507t3bvX5eN06dKlSCNo/fv3d/xss9nUv39/Xbx4UUuXLnW5hr+Sl5enJUuW6MEHH1Tt2rUd7dWqVdNjjz2mNWvWKDMz02mbvn37Ov0N3HXXXcrLy9OhQ4dKrE7gzwg7QDHJy8vTrFmz1LZtWx04cED79u3Tvn37FBkZqWPHjmnZsmWOvv369VP9+vXVsWNHVa9eXU888YQWL15c6H7r1avn9LpixYqqVq2a4zbRpTfYu+++2xE4Li1LlizR8ePHJckxd6ZJkybFfery8fFRYmKiEhMTlZCQoEaNGun48eNO4Ub6/ZbTG2+8ofDwcNntdlWpUkXBwcFKT093mhNTFIcOHVK9evUKPB116bbXtb6pnj17VpLk5+d32T4jRoxQenq66tevr6ZNm+rFF1/U9u3bi3ScWrVqXXVfDw8Pp7AhSfXr15ekEn1c/8SJEzp37pwaNGhQYF2jRo2Un5+vI0eOOLX/OVhfuq1Z2LwzoKQwZwcoJsuXL1dqaqpmzZqlWbNmFVg/ffp0dejQQZIUEhKirVu36ocfftD333+v77//XgkJCXr88ceLPLH20ryOL774QqGhoQXWX4/Hhj09PdW+fXvH6+joaDVs2FBPP/20FixY4GgfMGCAEhIS9Pzzz6tly5YKCAiQzWZTt27dLjs/xd127NghSVf8+IDWrVsrJSVF8+fP15IlS/Tf//5XH3zwgSZPnqwnn3zyqo7z52B4rS43WvfHEcbrwdPTs9B284fJ1EBJI+wAxWT69OkKCQlxPNnyR3PmzNHcuXM1efJkx5uat7e3YmJiFBMTo/z8fPXr10+ffPKJXn/9dac31r179zpui0m/jzSkpqaqU6dOkqQ6depI+j1A/TFw/NmlkYBLb96Xc623tKTfb2sMGjRIw4cP17p163T77bdLkr755hvFxsbq/fffd/S9cOFCgQ8wLEoNNWvW1Pbt25Wfn+80urN7927Helfl5eVpxowZKl++vFq1anXFvkFBQerdu7d69+6ts2fPqnXr1ho2bJgj7BTHdb0kPz9f+/fvd4zmSNKePXskyTEZ/dIIyp+vbWEjXVdbW3BwsMqXL6/k5OQC63bv3i0PDw+Fh4df1b6A64nbWEAxOH/+vObMmaP77rtPjzzySIGlf//+OnPmjGOU4+TJk07be3h46MYbb5QkZWdnO6379NNPlZOT43g9adIk5ebmqmPHjpJ+H0Xx9/fX22+/7dTvkkuP+QYHB6t169b67LPPdPjwYac+f/xXdoUKFSQVfJMsqgEDBqh8+fIaPXq0o83T07PAv+jHjx9fYLShKDV06tRJaWlpTk/35Obmavz48apYsaLatGnjUv15eXkaOHCgdu3apYEDB8rf3/+yff/8+6xYsaLq1q3r9Lssrut6yccff+z42Rijjz/+WOXKlVO7du0k/R7yPD09tXr1aqftJk6cWGBfV1ubp6enOnTooPnz5zvdLjt27JhmzJihVq1aXfE6Ae7CyA5QDBYsWKAzZ87o/vvvL3T97bffruDgYE2fPl1du3bVk08+qVOnTunuu+9W9erVdejQIY0fP1433XRTgUesL168qHbt2unRRx9VcnKyJk6cqFatWjmO5e/vr0mTJqlXr1665ZZb1K1bNwUHB+vw4cP67rvvdOeddzreGD/66CO1atVKt9xyi/r27atatWrp4MGD+u6777R161ZJUvPmzSVJr776qrp166Zy5copJibG8YZ4tSpXrqzevXtr4sSJ2rVrlxo1aqT77rtPX3zxhQICAtS4cWMlJSVp6dKlqly5stO2N910kzw9PfXOO+8oIyNDdrtdd999t0JCQgocp2/fvvrkk08UFxenTZs2KSIiQt98841++uknjRs37opzbS7JyMjQl19+KUk6d+6c4xOUU1JS1K1bN40cOfKK2zdu3FhRUVFq3ry5goKCtHHjRn3zzTdOk4gvXdeBAwcqOjpanp6e6tat21/WVhgfHx8tXrxYsbGxioyM1Pfff6/vvvtO//73vx2TnAMCAvTPf/5T48ePl81mU506dbRw4ULHHK4/Kkptb775phITE9WqVSv169dPXl5e+uSTT5Sdna0xY8a4dD5AiXPvw2CANcTExBgfHx+TlZV12T5xcXGmXLly5rfffjPffPON6dChgwkJCTHe3t6mRo0a5umnnzapqamO/pce3V21apXp27evqVSpkqlYsaLp0aOHOXnyZIH9r1ixwkRHR5uAgADj4+Nj6tSpY+Li4szGjRud+u3YscM89NBDJjAw0Pj4+JgGDRqY119/3anPyJEjzT/+8Q/j4eHxl4+hX3r0vDApKSnG09PT8Zj26dOnTe/evU2VKlVMxYoVTXR0tNm9e3eBR7mNMeY///mPqV27tvH09HR6hPrPj54bY8yxY8cc+/X29jZNmzZ1erT6Stq0aWMkOZaKFSuaevXqmZ49e5olS5YUus2f633zzTdNixYtTGBgoPH19TUNGzY0b731ltNHBuTm5poBAwaY4OBgY7PZHI96X3oU/N133y1wnMs9el6hQgWTkpJiOnToYMqXL2+qVq1qhg4davLy8py2P3HihOnSpYspX768qVSpknn66afNjh07CuzzcrUZU/DRc2OM2bx5s4mOjjYVK1Y05cuXN23btjVr16516nPp73fDhg1O7Zd7JB4oSTZjmCUGlEZTp05V7969tWHDBt16663uLgcAyizm7AAAAEsj7AAAAEsj7AAAAEtjzg4AALA0RnYAAIClEXYAAICl8aGC+v2j148ePSo/P79i/Uh3AABQcowxOnPmjMLCwgp8GfAfEXYkHT16lO9zAQCgjDpy5IiqV69+2fWEHcnxcfJHjhzhe10AACgjMjMzFR4e/pdfC0PY0f9946+/vz9hBwCAMuavpqAwQRkAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFiaW8POqFGjdNttt8nPz08hISF68MEHlZyc7NTnwoULio+PV+XKlVWxYkV16dJFx44dc+pz+PBhde7cWeXLl1dISIhefPFF5ebmXs9TAQAApZRbw86qVasUHx+vdevWKTExUTk5OerQoYOysrIcfQYNGqRvv/1Ws2fP1qpVq3T06FE9/PDDjvV5eXnq3LmzLl68qLVr1+rzzz/X1KlT9cYbb7jjlAAAQCljM8YYdxdxyYkTJxQSEqJVq1apdevWysjIUHBwsGbMmKFHHnlEkrR79241atRISUlJuv322/X999/rvvvu09GjR1W1alVJ0uTJk/Xyyy/rxIkT8vb2/svjZmZmKiAgQBkZGXw3FgAAZcTVvn+Xqjk7GRkZkqSgoCBJ0qZNm5STk6P27ds7+jRs2FA1atRQUlKSJCkpKUlNmzZ1BB1Jio6OVmZmpnbu3FnocbKzs5WZmem0AAAAayo1YSc/P1/PP/+87rzzTjVp0kSSlJaWJm9vbwUGBjr1rVq1qtLS0hx9/hh0Lq2/tK4wo0aNUkBAgGMJDw8v5rMBAAClRakJO/Hx8dqxY4dmzZpV4scaMmSIMjIyHMuRI0dK/JgAAMA9vNxdgCT1799fCxcu1OrVq1W9enVHe2hoqC5evKj09HSn0Z1jx44pNDTU0efnn3922t+lp7Uu9fkzu90uu91ezGcBoLSKeOW7EtnvwdGdS2S/AIqXW0d2jDHq37+/5s6dq+XLl6tWrVpO65s3b65y5cpp2bJljrbk5GQdPnxYLVu2lCS1bNlS//u//6vjx487+iQmJsrf31+NGze+PicCAABKLbeO7MTHx2vGjBmaP3++/Pz8HHNsAgIC5Ovrq4CAAPXp00eDBw9WUFCQ/P39NWDAALVs2VK33367JKlDhw5q3LixevXqpTFjxigtLU2vvfaa4uPjGb0BAADuDTuTJk2SJEVFRTm1JyQkKC4uTpL0wQcfyMPDQ126dFF2draio6M1ceJER19PT08tXLhQzz77rFq2bKkKFSooNjZWI0aMuF6nAQAASrFS9Tk77sLn7ADWxpwdwJrK5OfsAAAAFDfCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDS3hp3Vq1crJiZGYWFhstlsmjdvntN6m81W6PLuu+86+kRERBRYP3r06Ot8JgAAoLRya9jJyspSs2bNNGHChELXp6amOi2fffaZbDabunTp4tRvxIgRTv0GDBhwPcoHAABlgJc7D96xY0d17NjxsutDQ0OdXs+fP19t27ZV7dq1ndr9/PwK9AUAAJDK0JydY8eO6bvvvlOfPn0KrBs9erQqV66sm2++We+++65yc3OvuK/s7GxlZmY6LQAAwJrcOrJTFJ9//rn8/Pz08MMPO7UPHDhQt9xyi4KCgrR27VoNGTJEqampGjt27GX3NWrUKA0fPrykSwYAAKVAmQk7n332mXr06CEfHx+n9sGDBzt+vvHGG+Xt7a2nn35ao0aNkt1uL3RfQ4YMcdouMzNT4eHhJVM4AABwqzIRdn788UclJyfrq6+++su+kZGRys3N1cGDB9WgQYNC+9jt9ssGIQAAYC1lYs7OlClT1Lx5czVr1uwv+27dulUeHh4KCQm5DpUBAIDSzq0jO2fPntW+ffscrw8cOKCtW7cqKChINWrUkPT7LabZs2fr/fffL7B9UlKS1q9fr7Zt28rPz09JSUkaNGiQevbsqUqVKl238wAAAKWXW8POxo0b1bZtW8frS/NoYmNjNXXqVEnSrFmzZIxR9+7dC2xvt9s1a9YsDRs2TNnZ2apVq5YGDRrkNB8HAAD8vdmMMcbdRbhbZmamAgIClJGRIX9/f3eXA6CYRbzyXYns9+DoziWyXwBX52rfv8vEnB0AAABXEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAICluTXsrF69WjExMQoLC5PNZtO8efOc1sfFxclmszkt9957r1OfU6dOqUePHvL391dgYKD69Omjs2fPXsezAAAApZlbw05WVpaaNWumCRMmXLbPvffeq9TUVMcyc+ZMp/U9evTQzp07lZiYqIULF2r16tXq27dvSZcOAADKCC93Hrxjx47q2LHjFfvY7XaFhoYWum7Xrl1avHixNmzYoFtvvVWSNH78eHXq1EnvvfeewsLCir1mAABQtpT6OTsrV65USEiIGjRooGeffVYnT550rEtKSlJgYKAj6EhS+/bt5eHhofXr1192n9nZ2crMzHRaAACANZXqsHPvvfdq2rRpWrZsmd555x2tWrVKHTt2VF5eniQpLS1NISEhTtt4eXkpKChIaWlpl93vqFGjFBAQ4FjCw8NL9DwAAID7uPU21l/p1q2b4+emTZvqxhtvVJ06dbRy5Uq1a9fO5f0OGTJEgwcPdrzOzMwk8AAAYFGlemTnz2rXrq0qVapo3759kqTQ0FAdP37cqU9ubq5OnTp12Xk+0u/zgPz9/Z0WAABgTWUq7Pz66686efKkqlWrJklq2bKl0tPTtWnTJkef5cuXKz8/X5GRke4qEwAAlCJuvY119uxZxyiNJB04cEBbt25VUFCQgoKCNHz4cHXp0kWhoaFKSUnRSy+9pLp16yo6OlqS1KhRI91777166qmnNHnyZOXk5Kh///7q1q0bT2IBAABJbh7Z2bhxo26++WbdfPPNkqTBgwfr5ptv1htvvCFPT09t375d999/v+rXr68+ffqoefPm+vHHH2W32x37mD59uho2bKh27dqpU6dOatWqlT799FN3nRIAAChl3DqyExUVJWPMZdf/8MMPf7mPoKAgzZgxozjLAgAAFlKm5uwAAAAUFWEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYmlvDzurVqxUTE6OwsDDZbDbNmzfPsS4nJ0cvv/yymjZtqgoVKigsLEyPP/64jh496rSPiIgI2Ww2p2X06NHX+UwAAEBp5dawk5WVpWbNmmnChAkF1p07d06bN2/W66+/rs2bN2vOnDlKTk7W/fffX6DviBEjlJqa6lgGDBhwPcoHAABlgJc7D96xY0d17Nix0HUBAQFKTEx0avv444/VokULHT58WDVq1HC0+/n5KTQ0tERrBQAAZVOZmrOTkZEhm82mwMBAp/bRo0ercuXKuvnmm/Xuu+8qNzfXPQUCAIBSx60jO0Vx4cIFvfzyy+revbv8/f0d7QMHDtQtt9yioKAgrV27VkOGDFFqaqrGjh172X1lZ2crOzvb8TozM7NEawcAAO5TJsJOTk6OHn30URljNGnSJKd1gwcPdvx84403ytvbW08//bRGjRolu91e6P5GjRql4cOHl2jNAACgdCj1t7EuBZ1Dhw4pMTHRaVSnMJGRkcrNzdXBgwcv22fIkCHKyMhwLEeOHCnmqgEAQGlRqkd2LgWdvXv3asWKFapcufJfbrN161Z5eHgoJCTksn3sdvtlR30AAIC1uBR29u/fr9q1a1/zwc+ePat9+/Y5Xh84cEBbt25VUFCQqlWrpkceeUSbN2/WwoULlZeXp7S0NElSUFCQvL29lZSUpPXr16tt27by8/NTUlKSBg0apJ49e6pSpUrXXB8AACj7bMYYU9SNPDw81KZNG/Xp00ePPPKIfHx8XDr4ypUr1bZt2wLtsbGxGjZsmGrVqlXoditWrFBUVJQ2b96sfv36affu3crOzlatWrXUq1cvDR48uEgjN5mZmQoICFBGRsZf3iYDUPZEvPJdiez34OjOJbJfAFfnat+/XQo7W7duVUJCgmbOnKmLFy+qa9eu6tOnj1q0aHFNRbsLYQewNsIOYE1X+/7t0gTlm266SR9++KGOHj2qzz77TKmpqWrVqpWaNGmisWPH6sSJEy4XDgAAUJyu6WksLy8vPfzww5o9e7beeecd7du3Ty+88ILCw8P1+OOPKzU1tbjqBAAAcMk1hZ2NGzeqX79+qlatmsaOHasXXnhBKSkpSkxM1NGjR/XAAw8UV50AAAAucelprLFjxyohIUHJycnq1KmTpk2bpk6dOsnD4/fsVKtWLU2dOlURERHFWSsAAECRuRR2Jk2apCeeeEJxcXGqVq1aoX1CQkI0ZcqUayoOAADgWrkUdvbu3fuXfby9vRUbG+vK7gEAAIqNS3N2EhISNHv27ALts2fP1ueff37NRQEAABQXl8LOqFGjVKVKlQLtISEhevvtt6+5KAAAgOLiUtg5fPhwoZ9uXLNmTR0+fPiaiwIAACguLoWdkJAQbd++vUD7tm3brurLOgEAAK4Xl8JO9+7dNXDgQK1YsUJ5eXnKy8vT8uXL9dxzz6lbt27FXSMAAIDLXHoaa+TIkTp48KDatWsnL6/fd5Gfn6/HH3+cOTsAAKBUcSnseHt766uvvtLIkSO1bds2+fr6qmnTpqpZs2Zx1wcAAHBNXAo7l9SvX1/169cvrloAAACKnUthJy8vT1OnTtWyZct0/Phx5efnO61fvnx5sRQHAABwrVwKO88995ymTp2qzp07q0mTJrLZbMVdFwAAQLFwKezMmjVLX3/9tTp16lTc9QAAABQrlx499/b2Vt26dYu7FgAAgGLnUtj517/+pQ8//FDGmOKuBwAAoFi5dBtrzZo1WrFihb7//nvdcMMNKleunNP6OXPmFEtxAAAA18qlsBMYGKiHHnqouGsBAAAodi6FnYSEhOKuAwAAoES4NGdHknJzc7V06VJ98sknOnPmjCTp6NGjOnv2bLEVBwAAcK1cGtk5dOiQ7r33Xh0+fFjZ2dm655575Ofnp3feeUfZ2dmaPHlycdcJAADgEpdGdp577jndeuutOn36tHx9fR3tDz30kJYtW1ZsxQEAAFwrl0Z2fvzxR61du1be3t5O7REREfp//+//FUthAAAAxcGlkZ38/Hzl5eUVaP/111/l5+d3zUUBAAAUF5fCTocOHTRu3DjHa5vNprNnz2ro0KF8hQQAAChVXLqN9f777ys6OlqNGzfWhQsX9Nhjj2nv3r2qUqWKZs6cWdw1AgAAuMylsFO9enVt27ZNs2bN0vbt23X27Fn16dNHPXr0cJqwDAAA4G4uhR1J8vLyUs+ePYuzFgAAgGLnUtiZNm3aFdc//vjjLhUDAABQ3FwKO88995zT65ycHJ07d07e3t4qX748YQcAAJQaLj2Ndfr0aafl7NmzSk5OVqtWrZigDAAAShWXvxvrz+rVq6fRo0cXGPW5ktWrVysmJkZhYWGy2WyaN2+e03pjjN544w1Vq1ZNvr6+at++vfbu3evU59SpU+rRo4f8/f0VGBioPn368P1cAADAodjCjvT7pOWjR49edf+srCw1a9ZMEyZMKHT9mDFj9NFHH2ny5Mlav369KlSooOjoaF24cMHRp0ePHtq5c6cSExO1cOFCrV69Wn379r3mcwEAANbg0pydBQsWOL02xig1NVUff/yx7rzzzqveT8eOHdWxY8dC1xljNG7cOL322mt64IEHJP0+Mbpq1aqaN2+eunXrpl27dmnx4sXasGGDbr31VknS+PHj1alTJ7333nsKCwtz5fQAAICFuBR2HnzwQafXNptNwcHBuvvuu/X+++8XR106cOCA0tLS1L59e0dbQECAIiMjlZSUpG7duikpKUmBgYGOoCNJ7du3l4eHh9avX6+HHnqo0H1nZ2crOzvb8TozM7NYagYAAKWPS2EnPz+/uOsoIC0tTZJUtWpVp/aqVas61qWlpSkkJMRpvZeXl4KCghx9CjNq1CgNHz68mCsGAAClUbHO2SkrhgwZooyMDMdy5MgRd5cEAABKiEsjO4MHD77qvmPHjnXlEAoNDZUkHTt2TNWqVXO0Hzt2TDfddJOjz/Hjx522y83N1alTpxzbF8Zut8tut7tUFwAAKFtcCjtbtmzRli1blJOTowYNGkiS9uzZI09PT91yyy2OfjabzeXCatWqpdDQUC1btswRbjIzM7V+/Xo9++yzkqSWLVsqPT1dmzZtUvPmzSVJy5cvV35+viIjI10+NgAAsA6Xwk5MTIz8/Pz0+eefq1KlSpJ+/6DB3r1766677tK//vWvq9rP2bNntW/fPsfrAwcOaOvWrQoKClKNGjX0/PPP680331S9evVUq1Ytvf766woLC3NMkG7UqJHuvfdePfXUU5o8ebJycnLUv39/devWjSexAACAJMlmjDFF3egf//iHlixZohtuuMGpfceOHerQocNVf9bOypUr1bZt2wLtsbGxmjp1qowxGjp0qD799FOlp6erVatWmjhxourXr+/oe+rUKfXv31/ffvutPDw81KVLF3300UeqWLHiVZ9PZmamAgIClJGRIX9//6veDkDZEPHKdyWy34OjO5fIfgFcnat9/3ZpZCczM1MnTpwo0H7ixAmdOXPmqvcTFRWlK2Utm82mESNGaMSIEZftExQUpBkzZlz1MQEAwN+LS09jPfTQQ+rdu7fmzJmjX3/9Vb/++qv+53/+R3369NHDDz9c3DUCAAC4zKWRncmTJ+uFF17QY489ppycnN935OWlPn366N133y3WAgEAAK6FS2GnfPnymjhxot59912lpKRIkurUqaMKFSoUa3EAAADX6po+VDA1NVWpqamqV6+eKlSocMX5NwAAAO7gUtg5efKk2rVrp/r166tTp05KTU2VJPXp0+eqHzsHAAC4HlwKO4MGDVK5cuV0+PBhlS9f3tHetWtXLV68uNiKAwAAuFYuzdlZsmSJfvjhB1WvXt2pvV69ejp06FCxFAYAAFAcXBrZycrKchrRueTUqVN85xQAAChVXAo7d911l6ZNm+Z4bbPZlJ+frzFjxhT6icgAAADu4tJtrDFjxqhdu3bauHGjLl68qJdeekk7d+7UqVOn9NNPPxV3jQAAAC5zaWSnSZMm2rNnj1q1aqUHHnhAWVlZevjhh7VlyxbVqVOnuGsEAABwWZFHdnJycnTvvfdq8uTJevXVV0uiJgAAgGJT5JGdcuXKafv27SVRCwAAQLFz6TZWz549NWXKlOKuBQAAoNi5NEE5NzdXn332mZYuXarmzZsX+E6ssWPHFktxAAAA16pIYWf//v2KiIjQjh07dMstt0iS9uzZ49THZrMVX3UAAADXqEhhp169ekpNTdWKFSsk/f71EB999JGqVq1aIsUBAABcqyLN2fnzt5p///33ysrKKtaCAAAAipNLE5Qv+XP4AQAAKG2KFHZsNluBOTnM0QEAAKVZkebsGGMUFxfn+LLPCxcu6JlnninwNNacOXOKr0IAAIBrUKSwExsb6/S6Z8+exVoMAABAcStS2ElISCipOgAAAErENU1QBgAAKO0IOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNJKfdiJiIhwfNv6H5f4+HhJUlRUVIF1zzzzjJurBgAApUWRvhvLHTZs2KC8vDzH6x07duiee+7RP//5T0fbU089pREjRjhely9f/rrWCAAASq9SH3aCg4OdXo8ePVp16tRRmzZtHG3ly5dXaGjo9S4NAACUAaX+NtYfXbx4UV9++aWeeOIJ2Ww2R/v06dNVpUoVNWnSREOGDNG5c+euuJ/s7GxlZmY6LQAAwJpK/cjOH82bN0/p6emKi4tztD322GOqWbOmwsLCtH37dr388stKTk7WnDlzLrufUaNGafjw4dehYgAA4G42Y4xxdxFXKzo6Wt7e3vr2228v22f58uVq166d9u3bpzp16hTaJzs7W9nZ2Y7XmZmZCg8PV0ZGhvz9/Yu9bgDuFfHKdyWy34OjO5fIfgFcnczMTAUEBPzl+3eZGdk5dOiQli5desURG0mKjIyUpCuGHbvdLrvdXuw1AgCA0qfMzNlJSEhQSEiIOne+8r+ktm7dKkmqVq3adagKAACUdmViZCc/P18JCQmKjY2Vl9f/lZySkqIZM2aoU6dOqly5srZv365BgwapdevWuvHGG91YMQAAKC3KRNhZunSpDh8+rCeeeMKp3dvbW0uXLtW4ceOUlZWl8PBwdenSRa+99pqbKgUAAKVNmQg7HTp0UGHzqMPDw7Vq1So3VAQAAMqKMjNnBwAAwBWEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmlOuwMGzZMNpvNaWnYsKFj/YULFxQfH6/KlSurYsWK6tKli44dO+bGigEAQGlTqsOOJN1www1KTU11LGvWrHGsGzRokL799lvNnj1bq1at0tGjR/Xwww+7sVoAAFDaeLm7gL/i5eWl0NDQAu0ZGRmaMmWKZsyYobvvvluSlJCQoEaNGmndunW6/fbbr3epAACgFCr1Izt79+5VWFiYateurR49eujw4cOSpE2bNiknJ0ft27d39G3YsKFq1KihpKSkK+4zOztbmZmZTgsAALCmUh12IiMjNXXqVC1evFiTJk3SgQMHdNddd+nMmTNKS0uTt7e3AgMDnbapWrWq0tLSrrjfUaNGKSAgwLGEh4eX4FkAAAB3KtW3sTp27Oj4+cYbb1RkZKRq1qypr7/+Wr6+vi7vd8iQIRo8eLDjdWZmJoEHAACLKtUjO38WGBio+vXra9++fQoNDdXFixeVnp7u1OfYsWOFzvH5I7vdLn9/f6cFAABYU5kKO2fPnlVKSoqqVaum5s2bq1y5clq2bJljfXJysg4fPqyWLVu6sUoAAFCalOrbWC+88IJiYmJUs2ZNHT16VEOHDpWnp6e6d++ugIAA9enTR4MHD1ZQUJD8/f01YMAAtWzZkiexAACAQ6kOO7/++qu6d++ukydPKjg4WK1atdK6desUHBwsSfrggw/k4eGhLl26KDs7W9HR0Zo4caKbqwYAAKWJzRhj3F2Eu2VmZiogIEAZGRnM3wEsKOKV70pkvwdHdy6R/QK4Olf7/l2m5uwAAAAUFWEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYWqkOO6NGjdJtt90mPz8/hYSE6MEHH1RycrJTn6ioKNlsNqflmWeecVPFAACgtCnVYWfVqlWKj4/XunXrlJiYqJycHHXo0EFZWVlO/Z566imlpqY6ljFjxripYgAAUNp4ubuAK1m8eLHT66lTpyokJESbNm1S69atHe3ly5dXaGjo9S4PAACUAaV6ZOfPMjIyJElBQUFO7dOnT1eVKlXUpEkTDRkyROfOnXNHeQAAoBQq1SM7f5Sfn6/nn39ed955p5o0aeJof+yxx1SzZk2FhYVp+/btevnll5WcnKw5c+Zcdl/Z2dnKzs52vM7MzCzR2gEAgPuUmbATHx+vHTt2aM2aNU7tffv2dfzctGlTVatWTe3atVNKSorq1KlT6L5GjRql4cOHl2i9AACgdCgTt7H69++vhQsXasWKFapevfoV+0ZGRkqS9u3bd9k+Q4YMUUZGhmM5cuRIsdYLAABKj1I9smOM0YABAzR37lytXLlStWrV+stttm7dKkmqVq3aZfvY7XbZ7fbiKhMAAJRipTrsxMfHa8aMGZo/f778/PyUlpYmSQoICJCvr69SUlI0Y8YMderUSZUrV9b27ds1aNAgtW7dWjfeeKObqwcAAKVBqQ47kyZNkvT7Bwf+UUJCguLi4uTt7a2lS5dq3LhxysrKUnh4uLp06aLXXnvNDdUCAIDSqFSHHWPMFdeHh4dr1apV16kaAABQFpWJCcoAAACuIuwAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLs0zYmTBhgiIiIuTj46PIyEj9/PPP7i4JAACUApYIO1999ZUGDx6soUOHavPmzWrWrJmio6N1/Phxd5cGAADczBJhZ+zYsXrqqafUu3dvNW7cWJMnT1b58uX12Wefubs0AADgZmU+7Fy8eFGbNm1S+/btHW0eHh5q3769kpKS3FgZAAAoDbzcXcC1+u2335SXl6eqVas6tVetWlW7d+8udJvs7GxlZ2c7XmdkZEiSMjMzS65QAG6Tn32uRPbL/2cA7nXpv0FjzBX7lfmw44pRo0Zp+PDhBdrDw8PdUA2AsipgnLsrACBJZ86cUUBAwGXXl/mwU6VKFXl6eurYsWNO7ceOHVNoaGih2wwZMkSDBw92vM7Pz9epU6dUuXJl2Wy2Eq23tMvMzFR4eLiOHDkif39/d5djWVzn64drfX1wna8PrrMzY4zOnDmjsLCwK/Yr82HH29tbzZs317Jly/Tggw9K+j28LFu2TP379y90G7vdLrvd7tQWGBhYwpWWLf7+/vyHdB1wna8frvX1wXW+PrjO/+dKIzqXlPmwI0mDBw9WbGysbr31VrVo0ULjxo1TVlaWevfu7e7SAACAm1ki7HTt2lUnTpzQG2+8obS0NN10001avHhxgUnLAADg78cSYUeS+vfvf9nbVrh6drtdQ4cOLXCbD8WL63z9cK2vD67z9cF1do3N/NXzWgAAAGVYmf9QQQAAgCsh7AAAAEsj7AAAAEsj7AAAAEsj7PwNTZgwQREREfLx8VFkZKR+/vnnK/ZPT09XfHy8qlWrJrvdrvr162vRokXXqdqyq6jXedy4cWrQoIF8fX0VHh6uQYMG6cKFC9ep2rJp9erViomJUVhYmGw2m+bNm/eX26xcuVK33HKL7Ha76tatq6lTp5Z4nWVdUa/znDlzdM899yg4OFj+/v5q2bKlfvjhh+tTbBnnyt/0JT/99JO8vLx00003lVh9ZRVh52/mq6++0uDBgzV06FBt3rxZzZo1U3R0tI4fP15o/4sXL+qee+7RwYMH9c033yg5OVn/+c9/9I9//OM6V162FPU6z5gxQ6+88oqGDh2qXbt2acqUKfrqq6/073//+zpXXrZkZWWpWbNmmjBhwlX1P3DggDp37qy2bdtq69atev755/Xkk0/yRvwXinqdV69erXvuuUeLFi3Spk2b1LZtW8XExGjLli0lXGnZV9RrfUl6eroef/xxtWvXroQqK+MM/lZatGhh4uPjHa/z8vJMWFiYGTVqVKH9J02aZGrXrm0uXrx4vUq0hKJe5/j4eHP33Xc7tQ0ePNjceeedJVqnlUgyc+fOvWKfl156ydxwww1ObV27djXR0dElWJm1XM11Lkzjxo3N8OHDi78gCyvKte7atat57bXXzNChQ02zZs1KtK6yiJGdv5GLFy9q06ZNat++vaPNw8ND7du3V1JSUqHbLFiwQC1btlR8fLyqVq2qJk2a6O2331ZeXt71KrvMceU633HHHdq0aZPjVtf+/fu1aNEiderU6brU/HeRlJTk9HuRpOjo6Mv+XlA88vPzdebMGQUFBbm7FEtKSEjQ/v37NXToUHeXUmpZ5hOU8dd+++035eXlFfgajapVq2r37t2FbrN//34tX75cPXr00KJFi7Rv3z7169dPOTk5/Id1Ga5c58cee0y//fabWrVqJWOMcnNz9cwzz3Abq5ilpaUV+nvJzMzU+fPn5evr66bKrO29997T2bNn9eijj7q7FMvZu3evXnnlFf3444/y8uIt/XIY2cEV5efnKyQkRJ9++qmaN2+url276tVXX9XkyZPdXZqlrFy5Um+//bYmTpyozZs3a86cOfruu+80cuRId5cGXJMZM2Zo+PDh+vrrrxUSEuLuciwlLy9Pjz32mIYPH6769eu7u5xSjRj4N1KlShV5enrq2LFjTu3Hjh1TaGhoodtUq1ZN5cqVk6enp6OtUaNGSktL08WLF+Xt7V2iNZdFrlzn119/Xb169dKTTz4pSWratKmysrLUt29fvfrqq/Lw4N8lxSE0NLTQ34u/vz+jOiVg1qxZevLJJzV79uwCtw9x7c6cOaONGzdqy5Ytju+GzM/PlzFGXl5eWrJkie6++243V1k68P+gfyPe3t5q3ry5li1b5mjLz8/XsmXL1LJly0K3ufPOO7Vv3z7l5+c72vbs2aNq1aoRdC7Dlet87ty5AoHmUsA0fH1dsWnZsqXT70WSEhMTL/t7getmzpyp3r17a+bMmercubO7y7Ekf39//e///q+2bt3qWJ555hk1aNBAW7duVWRkpLtLLD3cPEEa19msWbOM3W43U6dONb/88ovp27evCQwMNGlpacYYY3r16mVeeeUVR//Dhw8bPz8/079/f5OcnGwWLlxoQkJCzJtvvumuUygTinqdhw4davz8/MzMmTPN/v37zZIlS0ydOnXMo48+6q5TKBPOnDljtmzZYrZs2WIkmbFjx5otW7aYQ4cOGWOMeeWVV0yvXr0c/ffv32/Kly9vXnzxRbNr1y4zYcIE4+npaRYvXuyuUygTinqdp0+fbry8vMyECRNMamqqY0lPT3fXKZQZRb3Wf8bTWIUj7PwNjR8/3tSoUcN4e3ubFi1amHXr1jnWtWnTxsTGxjr1X7t2rYmMjDR2u93Url3bvPXWWyY3N/c6V132FOU65+TkmGHDhpk6deoYHx8fEx4ebvr162dOnz59/QsvQ1asWGEkFVguXdvY2FjTpk2bAtvcdNNNxtvb29SuXdskJCRc97rLmqJe5zZt2lyxPy7Plb/pPyLsFM5mDGPkAADAupizAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwD/v6ioKD3//PPXvJ9ly5apUaNGysvLu/aiXNStWze9//77bjs+UJoQdoC/iaSkJHl6epbK7yk6ePCgbDabtm7delX9Li1BQUFq06aNfvzxxyIdb+XKlbLZbEpPT3dqnzNnTrF80/xLL72k1157TZ6entq9e7dsNpvWrVvn1Of222+Xj4+PLly44Gi7cOGCfHx8NGXKFKe+vXv31muvvSZJstlsmjdvXoFjxsXF6cEHH3S8fu211/TWW28pIyPjms8HKOsIO8DfxJQpUzRgwACtXr1aR48edXc512Tp0qVKTU3V6tWrFRYWpvvuu6/At5m7IigoSH5+fte0jzVr1iglJUVdunSRJDVs2FChoaFauXKlo8+ZM2e0efNmBQcHO4WgpKQkZWdnO31TdV5enhYuXKj777+/SHU0adJEderU0ZdffnlN5wNYAWEH+Bs4e/asvvrqKz377LPq3Lmzpk6d6rT+9OnT6tGjh4KDg+Xr66t69eopISFB0v+NpsyaNUt33HGHfHx81KRJE61atcppHzt27FDHjh1VsWJFVa1aVb169dJvv/3mWJ+fn68xY8aobt26stvtqlGjht566y1JUq1atSRJN998s2w2m6Kioq54PpUrV1ZoaKiaNGmif//738rMzNT69esd67/44gvdeuut8vPzU2hoqB577DEdP37ccT5t27aVJFWqVEk2m01xcXGSCt7GOn36tB5//HFVqlRJ5cuXV8eOHbV3794r1jZr1izdc8898vHxcbS1bdvWKeysWbNG9evXV0xMjFP7ypUrVbNmTcf1kKS1a9eqXLlyuu2226543MLExMRo1qxZRd4OsBrCDvA38PXXX6thw4Zq0KCBevbsqc8++0x//Fq8119/Xb/88ou+//577dq1S5MmTVKVKlWc9vHiiy/qX//6l7Zs2aKWLVsqJiZGJ0+elCSlp6fr7rvv1s0336yNGzdq8eLFOnbsmB599FHH9kOGDNHo0aMdx5oxY4aqVq0qSfr5558l/d+IzZw5c67qvM6fP69p06ZJkry9vR3tOTk5GjlypLZt26Z58+bp4MGDjkATHh6u//mf/5EkJScnKzU1VR9++GGh+4+Li9PGjRu1YMECJSUlyRijTp06KScn57I1/fjjj7r11lud2tq2bas1a9YoNzdXkrRixQpFRUWpTZs2WrFihaPfihUrHEHskgULFigmJkY2m+2qrskftWjRQj///LOys7OLvC1gKe79HlIA18Mdd9xhxo0bZ4z5/RvWq1SpYlasWOFYHxMTY3r37l3otgcOHDCSzOjRox1tOTk5pnr16uadd94xxhgzcuRI06FDB6ftjhw5YiSZ5ORkk5mZaex2u/nPf/5zxWNs2bLliudxqZ+vr6+pUKGCsdlsRpJp3ry5uXjx4mW327Bhg5Fkzpw5Y4z5v2+W/vO3yrdp08Y899xzxhhj9uzZYySZn376ybH+t99+M76+vubrr7++7LECAgLMtGnTnNr27t1rJJm1a9caY4y57bbbzNdff22OHj1q7Ha7OX/+vDl37pyx2+3m888/d9q2Xr16ZuHChY7XkoyPj4+pUKGC0+Ll5WUeeOABp223bdtmJJmDBw9etl7g78DLTRkLwHWSnJysn3/+WXPnzpUkeXl5qWvXrpoyZYrjdtGzzz6rLl26aPPmzerQoYMefPBB3XHHHU77admypeNnLy8v3Xrrrdq1a5ckadu2bVqxYoUqVqxY4PgpKSlKT09Xdna22rVrVyzn9NVXX6lhw4basWOHXnrpJU2dOlXlypVzrN+0aZOGDRumbdu26fTp08rPz5ckHT58WI0bN76qY+zatUteXl6KjIx0tFWuXFkNGjRwnHdhzp8/73QLS5Lq1q2r6tWra+XKlbrhhhu0ZcsWtWnTRiEhIapRo4Zj1Cg7O9tpZGfXrl06evRogev2wQcfqH379k5tL7/8coGnv3x9fSVJ586du6pzBqyKsANY3JQpU5Sbm6uwsDBHmzFGdrtdH3/8sQICAtSxY0cdOnRIixYtUmJiotq1a6f4+Hi99957V3WMs2fPKiYmRu+8806BddWqVdP+/fuL7Xyk329F1atXT/Xq1VNubq4eeugh7dixQ3a7XVlZWYqOjlZ0dLSmT5+u4OBgHT58WNHR0bp48WKx1lGYKlWq6PTp0wXao6KitGLFCt14442qV6+eQkJCJMlxK8sYo7p16yo8PNyxzYIFCwrM/5Gk0NBQ1a1b16nNz8+vwNNlp06dkiQFBwcXx6kBZRZzdgALy83N1bRp0/T+++9r69atjmXbtm0KCwvTzJkzHX2Dg4MVGxurL7/8UuPGjdOnn37qtK8/PjWUm5urTZs2qVGjRpKkW265RTt37lRERITq1q3rtFSoUEH16tWTr6+vli1bVmidl+bbuPK5NI888oi8vLw0ceJESdLu3bt18uRJjR49WnfddZcaNmzomJxclOM1atRIubm5ThOfT548qeTk5CuODt1888365ZdfCrS3bdtWa9euVWJiotME7NatW2vlypVauXJlgfk68+fP1wMPPHD5k/8LO3bsUPXq1QvMvwL+bgg7gIUtXLhQp0+fVp8+fdSkSROnpUuXLo7Pc3njjTc0f/587du3Tzt37tTChQsdQeaSCRMmaO7cudq9e7fi4+N1+vRpPfHEE5Kk+Ph4nTp1St27d9eGDRuUkpKiH374Qb1791ZeXp58fHz08ssv66WXXtK0adOUkpKidevWOY4fEhIiX19fx8Tmonw2jM1m08CBAzV69GidO3dONWrUkLe3t8aPH6/9+/drwYIFBT47p2bNmrLZbFq4cKFOnDihs2fPFthvvXr19MADD+ipp57SmjVrtG3bNvXs2VP/+Mc/rhhAoqOjtWbNmgLtbdu2VVZWlj777DO1adPG0d6mTRutX79eP//8s1PYOX78uDZu3Kj77rvvqq/Fn/3444/q0KGDy9sDluHmOUMAStB9991nOnXqVOi69evXG0lm27ZtZuTIkaZRo0bG19fXBAUFmQceeMDs37/fGPN/k4JnzJhhWrRoYby9vU3jxo3N8uXLnfa3Z88e89BDD5nAwEDj6+trGjZsaJ5//nmTn59vjDEmLy/PvPnmm6ZmzZqmXLlypkaNGubtt992bP+f//zHhIeHGw8PD9OmTZtCa77cROasrCxTqVIlx4TpGTNmmIiICGO3203Lli3NggULCmw3YsQIExoaamw2m4mNjTXGOE9QNsaYU6dOmV69epmAgADj6+troqOjzZ49e654zU+ePGl8fHzM7t27C6yrWbOmkWRSU1Od2iMiIowkc/ToUUfbf//7X3PnnXcW2IckM3fu3ALtsbGxThOUz58/bwICAkxSUtIV6wX+DmzG/OH5UwD4k4MHD6pWrVrasmWLbrrpJneXUya8+OKLyszM1CeffOLyPu6//361atVKL730kkvbT5o0SXPnztWSJUtcrgGwCm5jAUAxe/XVV1WzZk3HU2CuaNWqlbp37+7y9uXKldP48eNd3h6wEkZ2AFwRIzsAyjrCDgAAsDRuYwEAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEv7/wAJ/fjwwgiHIgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_paths = glob(os.path.join(dataset_folder_path, 'train', 'labels', '*.txt'))\n",
        "\n",
        "box_widths, box_heights = [], []\n",
        "\n",
        "for label_file in label_paths:\n",
        "    with open(label_file, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            _, x, y, w, h = map(float, line.strip().split())\n",
        "            box_widths.append(w)\n",
        "            box_heights.append(h)\n",
        "\n",
        "print(\"Bounding box (normalized YOLO format):\")\n",
        "print(f\"Width  â†’ min: {min(box_widths):.4f}, mean: {np.mean(box_widths):.4f}\")\n",
        "print(f\"Height â†’ min: {min(box_heights):.4f}, mean: {np.mean(box_heights):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN9o53coGg4m",
        "outputId": "7e3dbaf6-a245-45c0-9e75-4878ef4fd311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bounding box (normalized YOLO format):\n",
            "Width  â†’ min: 0.0164, mean: 0.0464\n",
            "Height â†’ min: 0.0211, mean: 0.0518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check lighting and contrast\n",
        "\n",
        "sample_img = cv2.imread(train_images[0])\n",
        "gray = cv2.cvtColor(sample_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "plt.hist(gray.flatten(), bins=50)\n",
        "plt.title(\"Pixel Intensity Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "Jmxq6z8SGpr6",
        "outputId": "3d92364e-f29e-4eec-d50c-469327c9f089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Video Analysis - EDA"
      ],
      "metadata": {
        "id": "AhX5IJ4ZNV1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Video Loading"
      ],
      "metadata": {
        "id": "Ioarxd2VUAIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Em2VAjfmPFV7",
        "outputId": "423bce9f-a49f-45c0-82d8-9f384b4bbc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.243-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.243-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.243 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_video_files(folder_path):\n",
        "    \"\"\"\n",
        "    Returns a list of actual video file paths within a given folder, filtering out macOS specific files.\n",
        "    \"\"\"\n",
        "    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm', '.3gp', '.mpeg', '.ogv')\n",
        "    video_files = []\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: The path '{folder_path}' does not exist. Please check the path and try again.\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Searching for video files in: {folder_path}\")\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            # Exclude macOS resource fork files (prefixed with ._) and files inside __MACOSX directory\n",
        "            if not file.startswith('._') and '__MACOSX' not in root:\n",
        "                if file.lower().endswith(video_extensions):\n",
        "                    video_files.append(os.path.join(root, file))\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"No actual video files found with extensions {video_extensions} in '{folder_path}' or its subdirectories after filtering.\")\n",
        "\n",
        "    return video_files\n",
        "\n",
        "# Re-define extract_dir as it might have been lost in the kernel state\n",
        "extract_dir = '/content/drive/MyDrive/unzipped_videos'\n",
        "\n",
        "# Re-populate video_file_paths using the defined get_video_files function\n",
        "video_file_paths = get_video_files(extract_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPnn7iuBHQrO",
        "outputId": "63a2c912-95c4-444d-c380-9af9e19080db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for video files in: /content/drive/MyDrive/unzipped_videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Correctly define the path to the best performing model weights\n",
        "# model_path = 'runs/train/cricket_ball/weights/best.pt'\n",
        "model_path = '/content/best.pt'\n",
        "\n",
        "# Load the YOLO model from the correct path\n",
        "model = YOLO(model_path)\n",
        "\n",
        "ball_sizes = []\n",
        "\n",
        "# Use 'video_file_paths' from the earlier step, which contains the list of unzipped video files.\n",
        "# Sample 1-2 videos, or more if needed, ensuring video_file_paths is not empty.\n",
        "# Added a check for video_file_paths being empty to prevent errors if no videos were found.\n",
        "if not video_file_paths:\n",
        "    print(\"No video files found to analyze.\")\n",
        "else:\n",
        "    for video_path in video_file_paths[:2]:  # Sample 1â€“2 videos\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count = 0\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error: Could not open video file: {video_path}\")\n",
        "            continue\n",
        "\n",
        "        while cap.isOpened() and frame_count < 200: # Process up to 200 frames per video\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Perform prediction on the frame\n",
        "            results = model.predict(frame, conf=0.25, verbose=False)\n",
        "\n",
        "            # Extract bounding box sizes if detections are made\n",
        "            # Check if results[0].boxes exists and contains detections\n",
        "            if results and results[0].boxes and len(results[0].boxes.xyxy) > 0:\n",
        "                for box in results[0].boxes.xyxy.cpu().numpy():\n",
        "                    x1, y1, x2, y2 = box\n",
        "                    ball_sizes.append((x2 - x1, y2 - y1))\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "# Check if ball_sizes list is populated before calculating statistics\n",
        "if ball_sizes:\n",
        "    print(\"Mean ball size (pixels):\", np.mean(ball_sizes, axis=0))\n",
        "    print(\"Min ball size (pixels):\", np.min(ball_sizes, axis=0))\n",
        "    print(\"Max ball size (pixels):\", np.max(ball_sizes, axis=0))\n",
        "    print(\"Standard deviation of ball sizes (pixels):\", np.std(ball_sizes, axis=0))\n",
        "else:\n",
        "    print(\"No ball detections were made in the sampled videos to calculate size statistics.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQfmDe18G5wO",
        "outputId": "919d856e-bfeb-435c-9ce2-77f85d752865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Mean ball size (pixels): [     71.219      81.798]\n",
            "Min ball size (pixels): [     70.373      77.814]\n",
            "Max ball size (pixels): [     72.551      86.264]\n",
            "Standard deviation of ball sizes (pixels): [    0.80383      2.9537]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detections = 0\n",
        "frames = 0\n",
        "\n",
        "cap = cv2.VideoCapture(video_file_paths[0])\n",
        "\n",
        "while frames < 300:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model.predict(frame, conf=0.15, verbose=False)\n",
        "    # if len(results[0].boxes) > 0:\n",
        "    if results[0].boxes is not None and len(results[0].boxes.xyxy) > 0:\n",
        "        detections += 1\n",
        "\n",
        "    frames += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(f\"Detection rate: {detections / frames:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2jhrFBkNZLe",
        "outputId": "c1d9f713-32a2-463f-886a-85dae231bda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detection rate: 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "centers = []\n",
        "\n",
        "cap = cv2.VideoCapture(video_file_paths[0])\n",
        "frames = 0\n",
        "\n",
        "while frames < 300:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model.predict(frame, conf=0.15, verbose=False)\n",
        "\n",
        "    if results[0].boxes is not None and len(results[0].boxes.xyxy) > 0:\n",
        "        # Take the highest confidence detection\n",
        "        box = results[0].boxes.xyxy[0].cpu().numpy()\n",
        "        x1, y1, x2, y2 = box\n",
        "        centers.append(((x1 + x2) / 2, (y1 + y2) / 2))\n",
        "\n",
        "    frames += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "centers = np.array(centers)\n",
        "\n",
        "velocity = np.diff(centers, axis=0)\n",
        "speed = np.linalg.norm(velocity, axis=1)\n",
        "\n",
        "print(\"Mean pixel velocity:\", speed.mean())\n",
        "print(\"Max pixel velocity:\", speed.max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNLt87SjUNf4",
        "outputId": "485f3bd8-4590-4d0f-896e-c03d42a27194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean pixel velocity: 13.335515\n",
            "Max pixel velocity: 69.15878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity Check\n",
        "\n",
        "Strategy:\n",
        "\n",
        "* Run YOLO on a single test video\n",
        "\n",
        "* Use very low confidence threshold\n",
        "\n",
        "* Draw:\n",
        "\n",
        "  - Bounding box\n",
        "\n",
        "  - Centroid\n",
        "\n",
        "  - Frame index\n",
        "\n",
        "* Save a short annotated clip (10â€“15 seconds)\n",
        "\n",
        "\n",
        "This step directly validates:\n",
        "\n",
        "* â€œDetect the cricket ball centroidâ€ âœ…\n",
        "\n",
        "* Frame-wise annotation feasibility âœ…\n",
        "\n",
        "* Processed video generation âœ…"
      ],
      "metadata": {
        "id": "ftGnEi05aVeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Load\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "model = YOLO(\"/content/best.pt\")\n"
      ],
      "metadata": {
        "id": "c19dZVozUeKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = video_file_paths[2]\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "out = cv2.VideoWriter(\n",
        "    \"sanity_check_detection.mp4\",\n",
        "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "    fps,\n",
        "    (width, height)\n",
        ")\n",
        "\n",
        "frame_idx = 0\n",
        "MAX_FRAMES = int(fps * 10)  # ~10 seconds\n",
        "\n",
        "while cap.isOpened() and frame_idx < MAX_FRAMES:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model.predict(frame, conf=0.05, verbose=False)\n",
        "\n",
        "    if results[0].boxes is not None and len(results[0].boxes.xyxy) > 0:\n",
        "        # Take highest confidence detection\n",
        "        box = results[0].boxes.xyxy[0].cpu().numpy()\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "        cx = int((x1 + x2) / 2)\n",
        "        cy = int((y1 + y2) / 2)\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Draw centroid\n",
        "        cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
        "\n",
        "        # Label\n",
        "        cv2.putText(\n",
        "            frame,\n",
        "            f\"Ball | Frame {frame_idx}\",\n",
        "            (x1, y1 - 10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.6,\n",
        "            (0, 255, 0),\n",
        "            2\n",
        "        )\n",
        "\n",
        "    out.write(frame)\n",
        "    frame_idx += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Sanity check video saved as sanity_check_detection.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wXGx9JgbHlG",
        "outputId": "02ac2124-2931-47f0-a049-4eda7fbad416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check video saved as sanity_check_detection.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kalman Filter (Constant Velocity)"
      ],
      "metadata": {
        "id": "GGCwNf6KheKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class KalmanFilterCV:\n",
        "    def __init__(self, dt):\n",
        "        # State: [x, y, vx, vy]\n",
        "        self.dt = dt\n",
        "\n",
        "        self.x = np.zeros((4, 1))  # state vector\n",
        "        self.P = np.eye(4) * 500   # covariance\n",
        "\n",
        "        self.F = np.array([\n",
        "            [1, 0, dt, 0],\n",
        "            [0, 1, 0, dt],\n",
        "            [0, 0, 1,  0],\n",
        "            [0, 0, 0,  1]\n",
        "        ])\n",
        "\n",
        "        self.H = np.array([\n",
        "            [1, 0, 0, 0],\n",
        "            [0, 1, 0, 0]\n",
        "        ])\n",
        "\n",
        "        self.Q = np.diag([1, 1, 25, 25])   # process noise\n",
        "        self.R = np.diag([9, 9])           # measurement noise\n",
        "\n",
        "    def predict(self):\n",
        "        self.x = self.F @ self.x\n",
        "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
        "        return self.x[:2].flatten()\n",
        "\n",
        "    def update(self, z):\n",
        "        z = np.array(z).reshape(2, 1)\n",
        "        y = z - (self.H @ self.x)\n",
        "        S = self.H @ self.P @ self.H.T + self.R\n",
        "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
        "        self.x = self.x + (K @ y)\n",
        "        self.P = (np.eye(4) - K @ self.H) @ self.P\n"
      ],
      "metadata": {
        "id": "RyFuL50UbSMa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0g98T9eHULh",
        "outputId": "b56ce04a-7e22-4a18-cea4-aef9fc2c65de",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.245-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.245-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.245 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Loading and Inferencing on Test Videos"
      ],
      "metadata": {
        "id": "9GBLTeW9Tl3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import csv\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "CONF_THRES = 0.05\n",
        "MIN_MOTION_PX = 5\n",
        "INIT_CONSEC_FRAMES = 3\n",
        "MAX_PRED_FRAMES = 1  # 5 previously\n",
        "# ----------------------------------------\n",
        "\n",
        "# Load trained YOLO model\n",
        "model = YOLO(\"/content/best.pt\")\n",
        "\n",
        "video_path = video_file_paths[0]\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "dt = 1 / fps\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "out = cv2.VideoWriter(\n",
        "    \"tracked_output.mp4\",\n",
        "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "    fps,\n",
        "    (W, H)\n",
        ")\n",
        "\n",
        "csv_file = open(\"annotations.csv\", \"w\", newline=\"\")\n",
        "writer = csv.writer(csv_file)\n",
        "writer.writerow([\"frame\", \"x\", \"y\", \"visible\"])\n",
        "\n",
        "kf = KalmanFilterCV(dt)\n",
        "trajectory = []\n",
        "\n",
        "# Tracker state\n",
        "initialized = False\n",
        "consec_valid = 0\n",
        "prev_center = None\n",
        "frames_since_detection = 0\n",
        "\n",
        "MIN_DETECTION_FOR_TRACK = 5 # evidence threshold\n",
        "detection_count = 0\n",
        "frame_idx = 0\n",
        "\n",
        "# ---------------- MAIN LOOP ----------------\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    detection = None\n",
        "    center = None\n",
        "    visible = 0\n",
        "\n",
        "    # ---------------- YOLO DETECTION ----------------\n",
        "    results = model.predict(frame, conf=CONF_THRES, verbose=False)\n",
        "\n",
        "    if results[0].boxes is not None and len(results[0].boxes.xyxy) > 0:\n",
        "        box = results[0].boxes.xyxy[0].cpu().numpy()\n",
        "        x1, y1, x2, y2 = box\n",
        "        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
        "\n",
        "        if cy < 0.15 * H:\n",
        "            detection = None\n",
        "        else:\n",
        "            if not initialized:\n",
        "                # Before init â†’ trust YOLO loosely\n",
        "                detection = (cx, cy)\n",
        "            else:\n",
        "                # After init â†’ motion gating\n",
        "                motion = np.linalg.norm(np.array([cx, cy]) - np.array(prev_center))\n",
        "                if motion >= MIN_MOTION_PX:\n",
        "                    detection = (cx, cy)\n",
        "\n",
        "        if detection is not None:\n",
        "              detection_count += 1\n",
        "\n",
        "\n",
        "\n",
        "    if not initialized:\n",
        "        if detection is not None:\n",
        "            consec_valid += 1\n",
        "            prev_center = detection\n",
        "\n",
        "            if consec_valid >= INIT_CONSEC_FRAMES and detection_count >=MIN_DETECTION_FOR_TRACK:\n",
        "                # Initialize Kalman with first reliable detection\n",
        "                kf.x[:2] = np.array(detection).reshape(2, 1)\n",
        "                kf.x[2:] = 0\n",
        "                initialized = True\n",
        "                trajectory.clear()\n",
        "                frames_since_detection = 0\n",
        "        else:\n",
        "            consec_valid = 0\n",
        "\n",
        "\n",
        "        # During initialization â†’ always invisible\n",
        "        writer.writerow([frame_idx, -1, -1, 0])\n",
        "\n",
        "    # ---------------- TRACKING ----------------\n",
        "    else:\n",
        "        if detection is not None:\n",
        "            kf.update(detection)\n",
        "            center = detection\n",
        "            prev_center = center\n",
        "            frames_since_detection = 0\n",
        "            visible = 1\n",
        "        else:\n",
        "            frames_since_detection += 1\n",
        "            if frames_since_detection <= MAX_PRED_FRAMES:\n",
        "                center = kf.predict()\n",
        "                visible = 0\n",
        "            else:\n",
        "                # Lost track â†’ reset cleanly\n",
        "                initialized = False\n",
        "                consec_valid = 0\n",
        "                prev_center = None\n",
        "                trajectory.clear()\n",
        "                writer.writerow([frame_idx, -1, -1, 0])\n",
        "                out.write(frame)\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "        # ---------------- OUTPUT ----------------\n",
        "        if center is not None:\n",
        "            cx, cy = int(center[0]), int(center[1])\n",
        "            trajectory.append((cx, cy))\n",
        "            writer.writerow([frame_idx, cx, cy, visible])\n",
        "\n",
        "            # Draw centroid\n",
        "            cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
        "\n",
        "            # Draw trajectory\n",
        "            for i in range(1, len(trajectory)):\n",
        "                cv2.line(frame, trajectory[i-1], trajectory[i], (255, 0, 0), 2)\n",
        "        else:\n",
        "            writer.writerow([frame_idx, -1, -1, 0])\n",
        "\n",
        "    out.write(frame)\n",
        "    frame_idx += 1\n",
        "\n",
        "# ---------------- CLEANUP ----------------\n",
        "cap.release()\n",
        "out.release()\n",
        "csv_file.close()\n",
        "\n",
        "print(\"âœ… Tracking complete\")\n",
        "print(\"â†’ Video: tracked_output.mp4\")\n",
        "print(\"â†’ CSV  : annotations.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWWTgFDRh02E",
        "outputId": "69106a0e-1ea2-4b14-9f95-9b05b5903b87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "âœ… Tracking complete\n",
            "â†’ Video: tracked_output.mp4\n",
            "â†’ CSV  : annotations.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h-wQPH-KWSPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}